{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Salesforce Deal Analysis and Prediction\n",
                "\n",
                "## 1. Objective\n",
                "The primary goal of this analysis is to **predict the probability of winning current open deals** in the sales pipeline for the upcoming month. By analyzing historical deal data, we aim to:\n",
                "- Identify the key factors (stage, region, client type) that influence deal success.\n",
                "- Train a machine learning model to estimate the 'Win Probability' for every active deal.\n",
                "- Prioritize the sales team's efforts by highlighting high-value, high-probability opportunities expected to close soon.\n",
                "\n",
                "## 2. Data Sources\n",
                "We use data exported from Salesforce, specifically the workbook: `Comm Rptg _ ERM Opportunity Data for GC _ 01.29.2026.xlsb`. \n",
                "To ensure a robust model, we combine data from two tabs:\n",
                "1.  **LTM_Opportunity_Data**: Recent opportunities from the Last Twelve Months. This reflects the most current market conditions and sales process.\n",
                "2.  **L5Yrs_Opportunity_Data**: Historical opportunities from the Last 5 Years. This provides a larger volume of data to train a more statistically significant model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "# Set configuration for clearer output\n",
                "pd.set_option('display.max_columns', None)\n",
                "plt.style.use('ggplot')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 Data Loading and Merging\n",
                "We load both sheets and merge them. Crucially, we remove duplicates based on the Deal `Id`. This is necessary because the LTM (Last 12 Month) data is likely a subset of the 5-Year data. Without de-duplication, recent deals would be over-represented, potentially biasing the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Data from Multiple Sheets\n",
                "file_path = r'raw data/Comm Rptg _ ERM Opportunity Data for GC _ 01.29.2026.xlsb'\n",
                "\n",
                "try:\n",
                "    print(f\"Reading file: {file_path} ...\")\n",
                "    # Read both sheets using pyxlsb engine for accuracy with binary excel files\n",
                "    df_ltm = pd.read_excel(file_path, sheet_name='LTM_Opportunity_Data', engine='pyxlsb')\n",
                "    print(f\"Loaded LTM_Opportunity_Data: {df_ltm.shape} records.\")\n",
                "    \n",
                "    df_5yr = pd.read_excel(file_path, sheet_name='L5Yrs_Opportunity_Data', engine='pyxlsb')\n",
                "    print(f\"Loaded L5Yrs_Opportunity_Data: {df_5yr.shape} records.\")\n",
                "    \n",
                "    # Combine datasets\n",
                "    df = pd.concat([df_ltm, df_5yr], ignore_index=True)\n",
                "    \n",
                "    # De-duplicate based on 'Id' to ensure each unique deal is counted only once\n",
                "    if 'Id' in df.columns:\n",
                "        initial_len = len(df)\n",
                "        df = df.drop_duplicates(subset=['Id'])\n",
                "        print(f\"Combined shape after dropping ID duplicates: {df.shape} (Removed {initial_len - len(df)} duplicate rows)\")\n",
                "    else:\n",
                "        print(f\"Combined shape (no Id check): {df.shape}\")\n",
                "        \n",
                "    # Standardize column names (remove leading/trailing spaces)\n",
                "    df.columns = df.columns.str.strip()\n",
                "    \n",
                "except ValueError as ve:\n",
                "    print(f\"Sheet name error: {ve}. Please check exact sheet names in the Excel file.\")\n",
                "except ImportError:\n",
                "    print(\"Error: 'pyxlsb' library is missing. Please run: !pip install pyxlsb\")\n",
                "except Exception as e:\n",
                "    print(f\"Unexpected erro: {e}\")\n",
                "\n",
                "if 'df' in locals():\n",
                "    display(df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Preprocessing\n",
                "Raw sales data often contains messy formats or missing values. In this step, we:\n",
                "1.  **Map Columns**: Identify the correct columns even if naming varies slightly.\n",
                "2.  **Convert Data Types**: Ensure dates are real DateTime objects and Amounts are numbers (handling any currency symbols or text).\n",
                "3.  **Define Target Variable (`IsWon`)**: The model needs a clear 1 (Won) vs 0 (Lost) target. We derive this from the `IsWon` boolean flag or infer it from the `Stage` (e.g., \"Closed Won\").\n",
                "4.  **Split History vs. Active**: We separate \"Closed\" deals (for training) from \"Open\" deals (for prediction)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preprocessing & Mapping\n",
                "if 'df' in locals():\n",
                "    # Helper to find column case-insensitively\n",
                "    def get_col(df, name):\n",
                "        for c in df.columns:\n",
                "            if c.lower() == name.lower(): return c\n",
                "        return None\n",
                "\n",
                "    # Flexible Column Mapping\n",
                "    col_mapping = {\n",
                "        'Created Date': get_col(df, 'Created Date'),\n",
                "        'Expected Start Date': get_col(df, 'Expected Start Date'),\n",
                "        'Expected Close FP': get_col(df, 'Expected Close FP'),\n",
                "        'Amount': get_col(df, 'Un-Wtd Net Amount Converted') or get_col(df, 'Amount'), \n",
                "        'IsWon': get_col(df, 'IsWon'),\n",
                "        'IsClosed': get_col(df, 'IsClosed'),\n",
                "        'Stage': get_col(df, 'Stage'),\n",
                "        'Sales POD': get_col(df, 'Sales POD'),\n",
                "        'Region': get_col(df, 'Region')\n",
                "    }\n",
                "    \n",
                "    print(\"Column Mapping used:\", col_mapping)\n",
                "\n",
                "    # 1. Date Conversion: Essential for time-based filtering\n",
                "    for col in [col_mapping['Created Date'], col_mapping['Expected Start Date']]:\n",
                "        if col: df[col] = pd.to_datetime(df[col], errors='coerce')\n",
                "\n",
                "    # 2. Amount Cleaning: Convert to numeric, treating errors as 0\n",
                "    if col_mapping['Amount']:\n",
                "        df['Amount'] = pd.to_numeric(df[col_mapping['Amount']], errors='coerce').fillna(0)\n",
                "    else:\n",
                "        df['Amount'] = 0\n",
                "\n",
                "    # 3. Create Target Variable (IsWon_Target)\n",
                "    # This is what the model tries to predict: 1 = Deal Won, 0 = Deal Lost\n",
                "    if col_mapping['IsWon']:\n",
                "        df['IsWon_Target'] = df[col_mapping['IsWon']].astype(str).apply(lambda x: 1 if x.lower() in ['1', 'true', 'yes', 'won'] else 0)\n",
                "    elif col_mapping['Stage']:\n",
                "        # Fallback: Inference from Stage name\n",
                "        df['IsWon_Target'] = df[col_mapping['Stage']].apply(lambda x: 1 if str(x).lower() == 'closed won' else 0)\n",
                "\n",
                "    # 4. Define Historical (Training) vs Active (Prediction) Data\n",
                "    if col_mapping['IsClosed']:\n",
                "        df['IsClosed_Bool'] = df[col_mapping['IsClosed']].astype(str).apply(lambda x: True if x.lower() in ['true', '1', 'yes'] else False)\n",
                "    elif col_mapping['Stage']:\n",
                "        closed_stages = ['Closed Won', 'Closed Lost', 'Omitted', 'Declined', 'Duplicate']\n",
                "        df['IsClosed_Bool'] = df[col_mapping['Stage']].isin(closed_stages)\n",
                "    else:\n",
                "         df['IsClosed_Bool'] = True # Default to all closed if unsure\n",
                "            \n",
                "    # Quick Check on Data Volume\n",
                "    print(f\"Total Deals: {len(df)}\")\n",
                "    print(f\"Overall Win Rate (Historical): {df[df['IsClosed_Bool']]['IsWon_Target'].mean():.2%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Modeling (Random Forest)\n",
                "We use a **Random Forest Classifier**. This algorithm is chosen because:\n",
                "- It handles a mix of numerical frequencies (Amount) and categorical data (Region, Stage) very well.\n",
                "- It is less prone to overfitting than a single Decision Tree.\n",
                "- It provides \"probabilities\" out of the box, not just a yes/no prediction.\n",
                "\n",
                "**Features Used:**\n",
                "- `Stage`: The current progress of the deal (highly predictive).\n",
                "- `Region` & `Sales POD`: Geographic or team-based factors.\n",
                "- `Client Type`: The nature of the customer.\n",
                "- `Business Unit`: The internal unit handling the deal.\n",
                "- `Amount`: The size of the deal."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if 'df' in locals():\n",
                "    # Select Features\n",
                "    feats = ['Stage', 'Region', 'Sales POD', 'Client Type', 'Business Unit', 'Amount']\n",
                "    \n",
                "    # Only use features that actually exist in the file\n",
                "    valid_feats = [f for f in feats if (f == 'Amount' or get_col(df, f))]\n",
                "    selected_cols = []\n",
                "    for f in valid_feats:\n",
                "        if f == 'Amount': selected_cols.append('Amount')\n",
                "        else: selected_cols.append(get_col(df, f))\n",
                "    \n",
                "    print(f\"Features selected for training: {selected_cols}\")\n",
                "\n",
                "    # Split Data\n",
                "    historical_df = df[df['IsClosed_Bool'] == True].copy()\n",
                "    active_df = df[df['IsClosed_Bool'] == False].copy()\n",
                "    \n",
                "    if not historical_df.empty:\n",
                "        X = historical_df[selected_cols].copy()\n",
                "        y = historical_df['IsWon_Target']\n",
                "        \n",
                "        # Handle Missing Values (Imputation)\n",
                "        for c in selected_cols:\n",
                "            if X[c].dtype == 'object': X[c] = X[c].fillna('Unknown')\n",
                "            else: X[c] = X[c].fillna(0)\n",
                "                \n",
                "        # Feature Encoding (Convert text to numbers)\n",
                "        encoders = {}\n",
                "        for c in X.select_dtypes(include=['object']).columns:\n",
                "            le = LabelEncoder()\n",
                "            # We fit on ALL data (Closed + Open) to ensure we know all categories\n",
                "            combined = pd.concat([df[c].astype(str), pd.Series(['Unknown'])], axis=0)\n",
                "            le.fit(combined)\n",
                "            encoders[c] = le\n",
                "            X[c] = le.transform(X[c].astype(str))\n",
                "            \n",
                "        # Train the Model\n",
                "        rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "        rf.fit(X, y)\n",
                "        print(\"\\nModel successfully trained on historical data.\")\n",
                "        \n",
                "        # Optional: Check accuracy on training set (or a split) to sanity check\n",
                "        # Here we just print feature importance\n",
                "        importances = pd.Series(rf.feature_importances_, index=selected_cols).sort_values(ascending=False)\n",
                "        plt.figure(figsize=(10,4))\n",
                "        importances.plot(kind='bar')\n",
                "        plt.title(\"Top Predictive Features\")\n",
                "        plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Forecasting Next Month's Deals\n",
                "Now we apply the trained model to the **Active (Open)** deals.\n",
                "1.  **Score Deals**: Calculate the `Win_Probability` for each open deal.\n",
                "2.  **Calculate Expected Value**: `Amount` * `Win_Probability`. This gives a risk-adjusted view of the pipeline.\n",
                "3.  **Filter Timeframe**: We look for deals with an `Expected Close FP` (Fiscal Period) falling in the next month (e.g., 2026-02 to 2026-03).\n",
                "4.  **Rank**: Sort deals by Expected Value to show where the team should focus."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if 'active_df' in locals() and not active_df.empty:\n",
                "    print(\"Preparing predictions for active deals...\")\n",
                "    \n",
                "    # Check if selected_cols exists (from Step 4)\n",
                "    if 'selected_cols' not in locals():\n",
                "        # Re-define if missing\n",
                "        feats = ['Stage', 'Region', 'Sales POD', 'Client Type', 'Business Unit', 'Amount']\n",
                "        valid_feats = [f for f in feats if (f == 'Amount' or get_col(df, f))]\n",
                "        selected_cols = []\n",
                "        for f in valid_feats:\n",
                "            if f == 'Amount': selected_cols.append('Amount')\n",
                "            else: selected_cols.append(get_col(df, f))\n",
                "    \n",
                "    # Check if encoders exists\n",
                "    if 'encoders' not in locals():\n",
                "        print(\"Error: 'encoders' not found. Please run the Model Training step first.\")\n",
                "    elif 'rf' not in locals():\n",
                "        print(\"Error: 'rf' (Model) not found. Please run the Model Training step first.\")\n",
                "    else:\n",
                "        # Prepare Active Data\n",
                "        X_act = active_df[selected_cols].copy()\n",
                "        \n",
                "        # Handle Missing Values\n",
                "        for c in selected_cols:\n",
                "            if X_act[c].dtype == 'object': \n",
                "                X_act[c] = X_act[c].fillna('Unknown')\n",
                "            else: \n",
                "                X_act[c] = X_act[c].fillna(0)\n",
                "        \n",
                "        # Safe Encoding\n",
                "        for c in X_act.select_dtypes(include=['object']).columns:\n",
                "            if c in encoders:\n",
                "                le = encoders[c]\n",
                "                # Safe Transform: Map unseen labels to 'Unknown'\n",
                "                # Ensure 'Unknown' is in classes (it was added in Step 4)\n",
                "                valid_classes = set(le.classes_)\n",
                "                \n",
                "                # Use apply to replace invalid labels\n",
                "                X_act[c] = X_act[c].astype(str).apply(lambda x: x if x in valid_classes else 'Unknown')\n",
                "                \n",
                "                # Transform\n",
                "                X_act[c] = le.transform(X_act[c])\n",
                "        \n",
                "        # Predict\n",
                "        try:\n",
                "            active_df['Win_Probability'] = rf.predict_proba(X_act)[:, 1]\n",
                "            active_df['Expected_Revenue'] = active_df['Amount'] * active_df['Win_Probability']\n",
                "            print(\"Predictions generated.\")\n",
                "            \n",
                "            # --- FILTER FOR NEXT MONTH ---\n",
                "            fp_col = col_mapping.get('Expected Close FP')\n",
                "            # Fallback to date if FP missing\n",
                "            date_col = col_mapping.get('Expected Start Date')\n",
                "            \n",
                "            next_month_deals = pd.DataFrame()\n",
                "            \n",
                "            if fp_col:\n",
                "                # Numeric FP Check\n",
                "                active_df['FP_Num'] = pd.to_numeric(active_df[fp_col], errors='coerce')\n",
                "                target_start, target_end = 202602, 202603\n",
                "                next_month_deals = active_df[active_df['FP_Num'].between(target_start, target_end)].copy()\n",
                "            elif date_col:\n",
                "                # Date Check (February 2026)\n",
                "                next_month_deals = active_df[\n",
                "                    (active_df[date_col].dt.year == 2026) & \n",
                "                    (active_df[date_col].dt.month.isin([2, 3]))\n",
                "                ].copy()\n",
                "                \n",
                "            if not next_month_deals.empty:\n",
                "                print(f\"\\n--- PREDICTION RESULTS ({len(next_month_deals)} deals found) ---\")\n",
                "                \n",
                "                # Display Config\n",
                "                disp_cols = ['Project', 'Stage', 'Amount', 'Win_Probability', 'Expected_Revenue']\n",
                "                final_disp = []\n",
                "                \n",
                "                # Map vars for display\n",
                "                if get_col(df, 'Project / Title'): \n",
                "                    next_month_deals['Project'] = next_month_deals[get_col(df, 'Project / Title')]\n",
                "                    final_disp.append('Project')\n",
                "                \n",
                "                stage_c = get_col(df, 'Stage')\n",
                "                if stage_c: \n",
                "                    next_month_deals['Stage'] = next_month_deals[stage_c]\n",
                "                    final_disp.append('Stage')\n",
                "                    \n",
                "                final_disp.extend(['Amount', 'Win_Probability', 'Expected_Revenue'])\n",
                "                \n",
                "                # Sort and Show\n",
                "                top_deals = next_month_deals.sort_values(by='Expected_Revenue', ascending=False).head(15)\n",
                "                \n",
                "                # Styling\n",
                "                try:\n",
                "                    display(top_deals[final_disp].style.format({\n",
                "                        'Amount': '${:,.0f}',\n",
                "                        'Expected_Revenue': '${:,.0f}',\n",
                "                        'Win_Probability': '{:.1%}'\n",
                "                    }))\n",
                "                except:\n",
                "                    # Fallback if style fails\n",
                "                    display(top_deals[final_disp])\n",
                "            else:\n",
                "                print(\"No deals found closing in the next month window (202602-202603). showing top active deals instead.\")\n",
                "                display(active_df.sort_values(by='Expected_Revenue', ascending=False).head(10))\n",
                "                \n",
                "        except Exception as e:\n",
                "            print(f\"Error during prediction calculation: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Anomaly Detection\n",
                "\n",
                "We identify potential data quality issues or unusual patterns in the active pipeline, such as:\n",
                "- **High Value Outliers**: Deals with unusually large amounts (> 99th percentile).\n",
                "- **Stagnant Deals**: Open deals that have been in the pipeline for over a year.\n",
                "- **Past Due Dates**: Deals marked as 'Open' but with start dates in the past.\n",
                "- **Data Gaps**: Deals with missing or zero dollar amounts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if 'active_df' in locals() and not active_df.empty:\n",
                "    print(\"\\n--- ANOMALY DETECTION REPORT ---\")\n",
                "    \n",
                "    # 1. High Value Deals (Outliers)\n",
                "    # Define threshold as 99th percentile to catch the top 1%\n",
                "    threshold = active_df['Amount'].quantile(0.99)\n",
                "    high_value = active_df[active_df['Amount'] > threshold].copy()\n",
                "    print(f\"\\n1. High Value Outliers (Top 1% > ${threshold:,.0f}): {len(high_value)} deals\")\n",
                "    \n",
                "    if not high_value.empty:\n",
                "        # Ensure project title is mapped\n",
                "        proj_col = get_col(df, 'Project / Title')\n",
                "        if proj_col:\n",
                "            high_value['Project'] = high_value[proj_col]\n",
                "        \n",
                "        display(high_value[['Project', 'Stage', 'Amount']].sort_values('Amount', ascending=False).head(5).style.format({'Amount': '${:,.0f}'}))\n",
                "    \n",
                "    # 2. Stagnant Deals (Old Creation Date)\n",
                "    # Deals open for more than 365 days\n",
                "    date_c = col_mapping.get('Created Date')\n",
                "    if date_c:\n",
                "        # Use a fixed reference date (today)\n",
                "        ref_date = pd.Timestamp.now()\n",
                "        active_df['Days_Open'] = (ref_date - active_df[date_c]).dt.days\n",
                "        stagnant = active_df[active_df['Days_Open'] > 365].copy()\n",
                "        print(f\"\\n2. Stagnant Deals (> 1 year old): {len(stagnant)} deals\")\n",
                "        if not stagnant.empty:\n",
                "             display(stagnant[['Days_Open', 'Stage', 'Amount']].sort_values('Days_Open', ascending=False).head(5))\n",
                "    \n",
                "    # 3. Past Due Dates\n",
                "    # Open deals where Expected Start Date is in the past\n",
                "    start_c = col_mapping.get('Expected Start Date')\n",
                "    if start_c:\n",
                "        past_due = active_df[active_df[start_c] < pd.Timestamp.now()].copy()\n",
                "        print(f\"\\n3. Past Due Start Dates: {len(past_due)} deals (Start Date is in past but deal is Open)\")\n",
                "        \n",
                "    # 4. Missing Critical Data\n",
                "    # Amount is 0 or negative\n",
                "    zero_amt = active_df[active_df['Amount'] <= 0]\n",
                "    print(f\"\\n4. Missing/Zero Amounts: {len(zero_amt)} deals have $0 value.\")\n",
                "    \n",
                "else:\n",
                "    print(\"Active DataFrame not found for anomaly checks.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}